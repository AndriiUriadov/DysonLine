"""
–î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è DysonianLineCNN
"""

import os
import numpy as np
from google.colab import drive
from config import PATHS


def check_gpu():
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å GPU —Ç–∞ –≤–∏–≤–æ–¥–∏—Ç—å —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –Ω—å–æ–≥–æ
    """
    try:
        import subprocess
        gpu_info = subprocess.check_output(['nvidia-smi']).decode()
        print("GPU Information:")
        print(gpu_info)
        return True
    except:
        print("Not connected to a GPU")
        return False


def check_ram():
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î –æ–±—Å—è–≥ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ—ó –ø–∞–º'—è—Ç—ñ
    """
    from psutil import virtual_memory
    ram_gb = virtual_memory().total / 1e9
    print(f'Your runtime has {ram_gb:.1f} gigabytes of available RAM')
    
    if ram_gb < 20:
        print('Not using a high-RAM runtime')
        return False
    else:
        print('You are using a high-RAM runtime!')
        return True


def mount_google_drive():
    """
    –ü—ñ–¥–∫–ª—é—á–∞—î Google Drive
    """
    if not os.path.ismount('/content/drive'):
        print("üîÑ Google Drive –Ω–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–æ. –ü—ñ–¥–∫–ª—é—á–∞—î–º–æ...")
        drive.mount('/content/drive')
    else:
        print("‚úÖ Google Drive –≤–∂–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–æ.")


def unmount_google_drive():
    """
    –í—ñ–¥–∫–ª—é—á–∞—î Google Drive
    """
    if os.path.ismount('/content/drive'):
        print("üîÑ Google Drive –ø—ñ–¥–∫–ª—é—á–µ–Ω–æ. –í—ñ–¥–∫–ª—é—á–∞—î–º–æ...")
        drive.flush_and_unmount()
    else:
        print("Google Drive –Ω–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–æ, –Ω–µ–º–∞ —á–æ–≥–æ –≤—ñ–¥–∫–ª—é—á–∞—Ç–∏.")


def save_model_to_drive(model, filename=None):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –º–æ–¥–µ–ª—å –Ω–∞ Google Drive
    
    Args:
        model: –º–æ–¥–µ–ª—å –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
        filename: —ñ–º'—è —Ñ–∞–π–ª—É (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ config)
    """
    if filename is None:
        filename = PATHS['google_drive_path']
    
    mount_google_drive()
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é —è–∫—â–æ –Ω–µ —ñ—Å–Ω—É—î
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –º–æ–¥–µ–ª—å
    model.save(filename)
    print(f"–ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}")


def load_model_from_drive(filename=None):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –º–æ–¥–µ–ª—å –∑ Google Drive
    
    Args:
        filename: —ñ–º'—è —Ñ–∞–π–ª—É (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º –∑ config)
        
    Returns:
        –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å
    """
    if filename is None:
        filename = PATHS['google_drive_path']
    
    mount_google_drive()
    
    if os.path.exists(filename):
        from tensorflow.keras.models import load_model
        model = load_model(filename)
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {filename}")
        return model
    else:
        print(f"–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {filename}")
        return None


def save_normalization_params(y_min, y_max, filename='normalization_params.npz'):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
    
    Args:
        y_min: –º—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        y_max: –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è
        filename: —ñ–º'—è —Ñ–∞–π–ª—É
    """
    np.savez(filename, y_min=y_min, y_max=y_max)
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}")


def load_normalization_params(filename='normalization_params.npz'):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó
    
    Args:
        filename: —ñ–º'—è —Ñ–∞–π–ª—É
        
    Returns:
        y_min, y_max
    """
    data = np.load(filename)
    y_min = data['y_min']
    y_max = data['y_max']
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {filename}")
    return y_min, y_max


def create_experiment_log(experiment_name, config_dict, metrics_dict=None):
    """
    –°—Ç–≤–æ—Ä—é—î –ª–æ–≥ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
    
    Args:
        experiment_name: –Ω–∞–∑–≤–∞ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
        config_dict: —Å–ª–æ–≤–Ω–∏–∫ –∑ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é
        metrics_dict: —Å–ª–æ–≤–Ω–∏–∫ –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
    """
    import json
    from datetime import datetime
    
    log_data = {
        'experiment_name': experiment_name,
        'timestamp': datetime.now().isoformat(),
        'config': config_dict,
        'metrics': metrics_dict
    }
    
    filename = f"experiment_log_{experiment_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    with open(filename, 'w') as f:
        json.dump(log_data, f, indent=2)
    
    print(f"–õ–æ–≥ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {filename}")


def print_system_info():
    """
    –í–∏–≤–æ–¥–∏—Ç—å —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Å–∏—Å—Ç–µ–º—É
    """
    print("=== System Information ===")
    
    # GPU
    gpu_available = check_gpu()
    
    # RAM
    ram_high = check_ram()
    
    # Python packages
    import tensorflow as tf
    print(f"TensorFlow version: {tf.__version__}")
    
    import numpy as np
    print(f"NumPy version: {np.__version__}")
    
    print("========================")
    
    return {
        'gpu_available': gpu_available,
        'ram_high': ram_high
    } 